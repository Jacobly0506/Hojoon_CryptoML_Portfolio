import os
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.callbacks import EarlyStopping
from datetime import datetime

# ===== ì„¤ì • =====
SEQ_LEN = 60
EPOCHS = 100
BATCH_SIZE = 32
MODEL_DIR = "models"
os.makedirs(MODEL_DIR, exist_ok=True)

# ===== ì‹œí€€ìŠ¤ ìƒì„± í•¨ìˆ˜ =====
def create_sequences(data, seq_len):
    X, y = [], []
    for i in range(len(data) - seq_len):
        X.append(data[i:i+seq_len])
        y.append(data[i+seq_len])
    return np.array(X), np.array(y)

# ===== ê°€ì¥ ìµœê·¼ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° =====
def get_latest_model_path(symbol: str):
    files = [f for f in os.listdir(MODEL_DIR) if f.startswith(f"{symbol.upper()}_1m")]
    if not files:
        return None
    files.sort(reverse=True)
    return os.path.join(MODEL_DIR, files[0])

# ===== ëª¨ë¸ êµ¬ì„± í•¨ìˆ˜ =====
def build_model(input_shape):
    model = Sequential([
        LSTM(64, return_sequences=False, input_shape=input_shape),
        Dense(32, activation="relu"),
        Dense(4)  # open, high, low, close
    ])
    model.compile(loss="mse", optimizer="adam")
    return model

# ===== í•™ìŠµ í•¨ìˆ˜ =====
def train_model(symbol: str, incremental=False):
    csv_path = f"data/{symbol.upper()}_1m.csv"
    if not os.path.exists(csv_path):
        print("âŒ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”.")
        return

    df = pd.read_csv(csv_path, header=None)
    df.columns = ["timestamp", "open", "high", "low", "close", "volume"]
    df = df.dropna()

    features = ["open", "high", "low", "close", "volume"]
    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(df[features])

    X, y = create_sequences(scaled_data, SEQ_LEN)
    y = y[:, :4]  # OHLCë§Œ ì˜ˆì¸¡

    if incremental:
        # ê°€ì¥ ìµœê·¼ ëª¨ë¸ ë¡œë“œ
        latest_model_path = get_latest_model_path(symbol)
        if latest_model_path:
            print(f"ğŸ“‚ ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ: {latest_model_path}")
            model = load_model(latest_model_path)
        else:
            print("âš ï¸ ê¸°ì¡´ ëª¨ë¸ì´ ì—†ì–´ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
            model = build_model((SEQ_LEN, len(features)))

        # ìµœê·¼ ë°ì´í„°ë¡œë§Œ í›ˆë ¨
        X_recent = X[-BATCH_SIZE:]
        y_recent = y[-BATCH_SIZE:]
        model.fit(X_recent, y_recent, epochs=1, verbose=1)

        # ë®ì–´ì“°ê¸°
        model.save(latest_model_path)
        print(f"ğŸ”„ ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {latest_model_path}")

    else:
        # ìƒˆ ëª¨ë¸ ìƒì„± ë° ì „ì²´ í•™ìŠµ
        model = build_model((SEQ_LEN, len(features)))
        early_stop = EarlyStopping(monitor="val_loss", patience=10, restore_best_weights=True)
        model.fit(
            X, y,
            epochs=EPOCHS,
            batch_size=BATCH_SIZE,
            validation_split=0.1,
            callbacks=[early_stop],
            verbose=1
        )
        timestamp = datetime.now().strftime("%Y%m%d_%H%M")
        model_path = os.path.join(MODEL_DIR, f"{symbol.upper()}_1m_{timestamp}.keras")
        model.save(model_path)
        print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")

# ===== ì‹¤í–‰ =====
if __name__ == "__main__":
    symbol = input("ğŸ“¥ ì‹¬ë³¼ ì…ë ¥ (ì˜ˆ: BTC): ").strip().upper()
    mode = input("ğŸ§  ëª¨ë“œ ì„ íƒ (full / incremental): ").strip().lower()
    incremental = mode == "incremental"
    train_model(symbol, incremental=incremental)
